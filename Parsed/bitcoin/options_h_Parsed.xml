<?xml version="1.0" encoding="UTF-8" standalone="yes"?>
<unit xmlns="http://www.srcML.org/srcML/src" xmlns:cpp="http://www.srcML.org/srcML/cpp" revision="1.0.0" language="C" filename="/home/mmm/Projects/bitcoin/src/leveldb/include/leveldb/options.h"><comment type="line">// Copyright (c) 2011 The LevelDB Authors. All rights reserved.</comment>
<comment type="line">// Use of this source code is governed by a BSD-style license that can be</comment>
<comment type="line">// found in the LICENSE file. See the AUTHORS file for names of contributors.</comment>

<cpp:ifndef>#<cpp:directive>ifndef</cpp:directive> <name>STORAGE_LEVELDB_INCLUDE_OPTIONS_H_</name></cpp:ifndef>
<cpp:define>#<cpp:directive>define</cpp:directive> <cpp:macro><name>STORAGE_LEVELDB_INCLUDE_OPTIONS_H_</name></cpp:macro></cpp:define>

<cpp:include>#<cpp:directive>include</cpp:directive> <cpp:file>&lt;stddef.h&gt;</cpp:file></cpp:include>

<decl_stmt><decl><type><name>namespace</name></type> <name>leveldb</name> <block>{<block_content>

<decl_stmt><decl><type><name>class</name></type> <name>Cache</name></decl>;</decl_stmt>
<decl_stmt><decl><type><name>class</name></type> <name>Comparator</name></decl>;</decl_stmt>
<decl_stmt><decl><type><name>class</name></type> <name>Env</name></decl>;</decl_stmt>
<decl_stmt><decl><type><name>class</name></type> <name>FilterPolicy</name></decl>;</decl_stmt>
<decl_stmt><decl><type><name>class</name></type> <name>Logger</name></decl>;</decl_stmt>
<decl_stmt><decl><type><name>class</name></type> <name>Snapshot</name></decl>;</decl_stmt>

<comment type="line">// DB contents are stored in a set of blocks, each of which holds a</comment>
<comment type="line">// sequence of key,value pairs.  Each block may be compressed before</comment>
<comment type="line">// being stored in a file.  The following enum describes which</comment>
<comment type="line">// compression method (if any) is used to compress a block.</comment>
<enum>enum <name>CompressionType</name> <block>{
  <comment type="line">// NOTE: do not change the values of existing entries, as these are</comment>
  <comment type="line">// part of the persistent format on disk.</comment>
  <decl><name>kNoCompression</name>     <init>= <expr><literal type="number">0x0</literal></expr></init></decl>,
  <decl><name>kSnappyCompression</name> <init>= <expr><literal type="number">0x1</literal></expr></init></decl>
}</block>;</enum>

<comment type="line">// Options to control the behavior of a database (passed to DB::Open)</comment>
<struct>struct <name>Options</name> <block>{
  <comment type="line">// -------------------</comment>
  <comment type="line">// Parameters that affect behavior</comment>

  <comment type="line">// Comparator used to define the order of keys in the table.</comment>
  <comment type="line">// Default: a comparator that uses lexicographic byte-wise ordering</comment>
  <comment type="line">//</comment>
  <comment type="line">// REQUIRES: The client must ensure that the comparator supplied</comment>
  <comment type="line">// here has the same name and orders keys *exactly* the same as the</comment>
  <comment type="line">// comparator provided to previous open calls on the same DB.</comment>
  <decl_stmt><decl><type><specifier>const</specifier> <name>Comparator</name><modifier>*</modifier></type> <name>comparator</name></decl>;</decl_stmt>

  <comment type="line">// If true, the database will be created if it is missing.</comment>
  <comment type="line">// Default: false</comment>
  <decl_stmt><decl><type><name>bool</name></type> <name>create_if_missing</name></decl>;</decl_stmt>

  <comment type="line">// If true, an error is raised if the database already exists.</comment>
  <comment type="line">// Default: false</comment>
  <decl_stmt><decl><type><name>bool</name></type> <name>error_if_exists</name></decl>;</decl_stmt>

  <comment type="line">// If true, the implementation will do aggressive checking of the</comment>
  <comment type="line">// data it is processing and will stop early if it detects any</comment>
  <comment type="line">// errors.  This may have unforeseen ramifications: for example, a</comment>
  <comment type="line">// corruption of one DB entry may cause a large number of entries to</comment>
  <comment type="line">// become unreadable or for the entire DB to become unopenable.</comment>
  <comment type="line">// Default: false</comment>
  <decl_stmt><decl><type><name>bool</name></type> <name>paranoid_checks</name></decl>;</decl_stmt>

  <comment type="line">// Use the specified object to interact with the environment,</comment>
  <comment type="line">// e.g. to read/write files, schedule background work, etc.</comment>
  <comment type="line">// Default: Env::Default()</comment>
  <decl_stmt><decl><type><name>Env</name><modifier>*</modifier></type> <name>env</name></decl>;</decl_stmt>

  <comment type="line">// Any internal progress/error information generated by the db will</comment>
  <comment type="line">// be written to info_log if it is non-NULL, or to a file stored</comment>
  <comment type="line">// in the same directory as the DB contents if info_log is NULL.</comment>
  <comment type="line">// Default: NULL</comment>
  <decl_stmt><decl><type><name>Logger</name><modifier>*</modifier></type> <name>info_log</name></decl>;</decl_stmt>

  <comment type="line">// -------------------</comment>
  <comment type="line">// Parameters that affect performance</comment>

  <comment type="line">// Amount of data to build up in memory (backed by an unsorted log</comment>
  <comment type="line">// on disk) before converting to a sorted on-disk file.</comment>
  <comment type="line">//</comment>
  <comment type="line">// Larger values increase performance, especially during bulk loads.</comment>
  <comment type="line">// Up to two write buffers may be held in memory at the same time,</comment>
  <comment type="line">// so you may wish to adjust this parameter to control memory usage.</comment>
  <comment type="line">// Also, a larger write buffer will result in a longer recovery time</comment>
  <comment type="line">// the next time the database is opened.</comment>
  <comment type="line">//</comment>
  <comment type="line">// Default: 4MB</comment>
  <decl_stmt><decl><type><name>size_t</name></type> <name>write_buffer_size</name></decl>;</decl_stmt>

  <comment type="line">// Number of open files that can be used by the DB.  You may need to</comment>
  <comment type="line">// increase this if your database has a large working set (budget</comment>
  <comment type="line">// one open file per 2MB of working set).</comment>
  <comment type="line">//</comment>
  <comment type="line">// Default: 1000</comment>
  <decl_stmt><decl><type><name>int</name></type> <name>max_open_files</name></decl>;</decl_stmt>

  <comment type="line">// Control over blocks (user data is stored in a set of blocks, and</comment>
  <comment type="line">// a block is the unit of reading from disk).</comment>

  <comment type="line">// If non-NULL, use the specified cache for blocks.</comment>
  <comment type="line">// If NULL, leveldb will automatically create and use an 8MB internal cache.</comment>
  <comment type="line">// Default: NULL</comment>
  <decl_stmt><decl><type><name>Cache</name><modifier>*</modifier></type> <name>block_cache</name></decl>;</decl_stmt>

  <comment type="line">// Approximate size of user data packed per block.  Note that the</comment>
  <comment type="line">// block size specified here corresponds to uncompressed data.  The</comment>
  <comment type="line">// actual size of the unit read from disk may be smaller if</comment>
  <comment type="line">// compression is enabled.  This parameter can be changed dynamically.</comment>
  <comment type="line">//</comment>
  <comment type="line">// Default: 4K</comment>
  <decl_stmt><decl><type><name>size_t</name></type> <name>block_size</name></decl>;</decl_stmt>

  <comment type="line">// Number of keys between restart points for delta encoding of keys.</comment>
  <comment type="line">// This parameter can be changed dynamically.  Most clients should</comment>
  <comment type="line">// leave this parameter alone.</comment>
  <comment type="line">//</comment>
  <comment type="line">// Default: 16</comment>
  <decl_stmt><decl><type><name>int</name></type> <name>block_restart_interval</name></decl>;</decl_stmt>

  <comment type="line">// Leveldb will write up to this amount of bytes to a file before</comment>
  <comment type="line">// switching to a new one.</comment>
  <comment type="line">// Most clients should leave this parameter alone.  However if your</comment>
  <comment type="line">// filesystem is more efficient with larger files, you could</comment>
  <comment type="line">// consider increasing the value.  The downside will be longer</comment>
  <comment type="line">// compactions and hence longer latency/performance hiccups.</comment>
  <comment type="line">// Another reason to increase this parameter might be when you are</comment>
  <comment type="line">// initially populating a large database.</comment>
  <comment type="line">//</comment>
  <comment type="line">// Default: 2MB</comment>
  <decl_stmt><decl><type><name>size_t</name></type> <name>max_file_size</name></decl>;</decl_stmt>

  <comment type="line">// Compress blocks using the specified compression algorithm.  This</comment>
  <comment type="line">// parameter can be changed dynamically.</comment>
  <comment type="line">//</comment>
  <comment type="line">// Default: kSnappyCompression, which gives lightweight but fast</comment>
  <comment type="line">// compression.</comment>
  <comment type="line">//</comment>
  <comment type="line">// Typical speeds of kSnappyCompression on an Intel(R) Core(TM)2 2.4GHz:</comment>
  <comment type="line">//    ~200-500MB/s compression</comment>
  <comment type="line">//    ~400-800MB/s decompression</comment>
  <comment type="line">// Note that these speeds are significantly faster than most</comment>
  <comment type="line">// persistent storage speeds, and therefore it is typically never</comment>
  <comment type="line">// worth switching to kNoCompression.  Even if the input data is</comment>
  <comment type="line">// incompressible, the kSnappyCompression implementation will</comment>
  <comment type="line">// efficiently detect that and will switch to uncompressed mode.</comment>
  <decl_stmt><decl><type><name>CompressionType</name></type> <name>compression</name></decl>;</decl_stmt>

  <comment type="line">// EXPERIMENTAL: If true, append to existing MANIFEST and log files</comment>
  <comment type="line">// when a database is opened.  This can significantly speed up open.</comment>
  <comment type="line">//</comment>
  <comment type="line">// Default: currently false, but may become true later.</comment>
  <decl_stmt><decl><type><name>bool</name></type> <name>reuse_logs</name></decl>;</decl_stmt>

  <comment type="line">// If non-NULL, use the specified filter policy to reduce disk reads.</comment>
  <comment type="line">// Many applications will benefit from passing the result of</comment>
  <comment type="line">// NewBloomFilterPolicy() here.</comment>
  <comment type="line">//</comment>
  <comment type="line">// Default: NULL</comment>
  <decl_stmt><decl><type><specifier>const</specifier> <name>FilterPolicy</name><modifier>*</modifier></type> <name>filter_policy</name></decl>;</decl_stmt>

  <comment type="line">// Create an Options object with default values for all fields.</comment>
  <expr_stmt><expr><call><name>Options</name><argument_list>()</argument_list></call></expr>;</expr_stmt>
}</block>;</struct>

<comment type="line">// Options that control read operations</comment>
<struct>struct <name>ReadOptions</name> <block>{
  <comment type="line">// If true, all data read from underlying storage will be</comment>
  <comment type="line">// verified against corresponding checksums.</comment>
  <comment type="line">// Default: false</comment>
  <decl_stmt><decl><type><name>bool</name></type> <name>verify_checksums</name></decl>;</decl_stmt>

  <comment type="line">// Should the data read for this iteration be cached in memory?</comment>
  <comment type="line">// Callers may wish to set this field to false for bulk scans.</comment>
  <comment type="line">// Default: true</comment>
  <decl_stmt><decl><type><name>bool</name></type> <name>fill_cache</name></decl>;</decl_stmt>

  <comment type="line">// If "snapshot" is non-NULL, read as of the supplied snapshot</comment>
  <comment type="line">// (which must belong to the DB that is being read and which must</comment>
  <comment type="line">// not have been released).  If "snapshot" is NULL, use an implicit</comment>
  <comment type="line">// snapshot of the state at the beginning of this read operation.</comment>
  <comment type="line">// Default: NULL</comment>
  <decl_stmt><decl><type><specifier>const</specifier> <name>Snapshot</name><modifier>*</modifier></type> <name>snapshot</name></decl>;</decl_stmt>

  <expr_stmt><expr><call><name>ReadOptions</name><argument_list>()</argument_list></call>
      <operator>:</operator> <call><name>verify_checksums</name><argument_list>(<argument><expr><name>false</name></expr></argument>)</argument_list></call></expr><operator>,</operator>
        <expr><call><name>fill_cache</name><argument_list>(<argument><expr><name>true</name></expr></argument>)</argument_list></call></expr><operator>,</operator>
        <macro><name>snapshot</name><argument_list>(<argument>NULL</argument>)</argument_list></macro> <expr><block>{
  }</block></expr></expr_stmt>
}</block>;</struct>

<comment type="line">// Options that control write operations</comment>
<struct>struct <name>WriteOptions</name> <block>{
  <comment type="line">// If true, the write will be flushed from the operating system</comment>
  <comment type="line">// buffer cache (by calling WritableFile::Sync()) before the write</comment>
  <comment type="line">// is considered complete.  If this flag is true, writes will be</comment>
  <comment type="line">// slower.</comment>
  <comment type="line">//</comment>
  <comment type="line">// If this flag is false, and the machine crashes, some recent</comment>
  <comment type="line">// writes may be lost.  Note that if it is just the process that</comment>
  <comment type="line">// crashes (i.e., the machine does not reboot), no writes will be</comment>
  <comment type="line">// lost even if sync==false.</comment>
  <comment type="line">//</comment>
  <comment type="line">// In other words, a DB write with sync==false has similar</comment>
  <comment type="line">// crash semantics as the "write()" system call.  A DB write</comment>
  <comment type="line">// with sync==true has similar crash semantics to a "write()"</comment>
  <comment type="line">// system call followed by "fsync()".</comment>
  <comment type="line">//</comment>
  <comment type="line">// Default: false</comment>
  <decl_stmt><decl><type><name>bool</name></type> <name>sync</name></decl>;</decl_stmt>

  <expr_stmt><expr><call><name>WriteOptions</name><argument_list>()</argument_list></call>
      <operator>:</operator> <macro><name>sync</name><argument_list>(<argument>false</argument>)</argument_list></macro> <block>{
  }</block></expr></expr_stmt>
}</block>;</struct>

</block_content>}</block></decl></decl_stmt>  <comment type="line">// namespace leveldb</comment>

<cpp:endif>#<cpp:directive>endif</cpp:directive></cpp:endif>  <comment type="line">// STORAGE_LEVELDB_INCLUDE_OPTIONS_H_</comment>
</unit>
